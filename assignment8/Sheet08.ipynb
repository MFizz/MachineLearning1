{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Exercise Sheet 07</h1>\n",
      "<h2>Expectation Maximization</h2>\n",
      "\n",
      "In this assignment we will be using the Expectation Maximization method to estimate the parameters of the three coin experiment. We will examine the results of the method for various combinations of $\\lambda$, $p_1$ and $p_2$. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import random as random\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Part 1: Generating the Data</h2>\n",
      "\n",
      "Implement a function which generates the data for the three coin experiment.\n",
      "\n",
      "The parameters are:\n",
      "\n",
      "- $\\lambda$ := The probability of heads on the secret coin S\n",
      "\n",
      "- $p_1$ := The probability of heads on coin A\n",
      "\n",
      "- $p_2$ := The probability of heads on coin B\n",
      "\n",
      "$N$ samples are collected the following way:\n",
      "\n",
      "- The secret coin (S) is tossed\n",
      "\n",
      "- If the result was heads, coin A is tossed $m$ times and the results are recorded\n",
      "\n",
      "- If the result was tails, coin B is tossed $m$ times and the results are recorded\n",
      "\n",
      "**Heads are recorded as 1.** \n",
      "\n",
      "**Tails are recorded as 0.**\n",
      "\n",
      "The data is returned as an **$m$x$N$** matrix, where each of the $N$ columns contains the results of the corresponding sample (generated eiher by coin A or by coin B). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generateData(lam, p1, p2, N, M):\n",
      "    \"\"\"\n",
      "    returns: An mxN matrix, containing 1 for heads and 0 for tails.\n",
      "    \"\"\"\n",
      "    \n",
      "    data = np.zeros((M,N))\n",
      "    for i in range(len(data[0])):\n",
      "        data[:,i] = np.array([random.random() for x in data])\n",
      "    \n",
      "    for i in range(len(data[0,:])):\n",
      "        rand = random.random()\n",
      "        if(rand < lam):\n",
      "            p = p1\n",
      "        else:\n",
      "            p = p2\n",
      "        data[:,i] = np.array([1 if x < p else 0 for x in data[:,i]])\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Part 2: Implementing EM for the model</h2>\n",
      "\n",
      "Implement a function which iteratively determines the values of $\\lambda$, $p_1$ and $p_2$. The function starts with some initial estimates for the parameters and returns the results of the method for those parameters.\n",
      "\n",
      "In each iteration, the following update rules are used for the parameters:\n",
      "\n",
      "<h2>$\\lambda^{new}$ $=$ $\\frac{E(\\#heads(coin\\_S))}{\\#throws(coin\\_S)}$ $=$ $\\frac{1}{N}\\sum_{i=1}^{N}\\frac{\\lambda p_1^{h(x_i)}(1-p_1)^{t(x_i)}}{\\lambda p_1^{h(x_i)}(1-p_1)^{t(x_i)}) + (1-\\lambda)p_2^{h(x_i)}(1-p_2)^{t(x_i)})}$</h2>  \n",
      "where $h(x_i)$ and $t(x_i)$ denote the number of heads and tails in sample i, respectively.\n",
      "\n",
      "<h3>Let us denote $R_1(i)$ =$\\frac{\\lambda p_1^{h(x_i)}(1-p_1)^{t(x_i)}}{\\lambda p_1^{h(x_i)}(1-p_1)^{t(x_i)}) + (1-\\lambda)p_2^{h(x_i)}(1-p_2)^{t(x_i)})}$</h3>\n",
      "\n",
      "<h3>And $R_2(i)$ = $\\frac{(1-\\lambda) p_2^{h(x_i)}(1-p_2)^{t(x_i)}}{\\lambda p_1^{h(x_i)}(1-p_1)^{t(x_i)}) + (1-\\lambda)p_2^{h(x_i)}(1-p_2)^{t(x_i)})}$</h3>\n",
      "\n",
      "The update rules for the remaining parameters are:\n",
      "\n",
      "<h2>$p_1^{new}$ $=$ $\\frac{E(\\#heads(coin\\_A))}{E(\\#throws(coin\\_A))}$ $=$ $\\frac{\\sum_{i=1}^{N}R_1(i)h(x_i)}{m\\sum_{i=1}^{N}R_1(i)}$</h2>\n",
      "\n",
      "<h2>$p_2^{new}$ $=$ $\\frac{E(\\#heads(coin\\_B))}{E(\\#throws(coin\\_B))}$ $=$ $\\frac{\\sum_{i=1}^{N}R_2(i)h(x_i)}{m\\sum_{i=1}^{N}R_2(i)}$</h2>\n",
      "\n",
      "\n",
      "Apply the update rule while |$\\lambda^{new}-\\lambda$| + |$p_1^{new}-p_1$| + |$p_2^{new}-p_2$| > t, where t is some small threshold."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def EM(lam,p1,p2,X,N,M):\n",
      "    r1 = np.zeros(N)\n",
      "    r2 = np.zeros(N)\n",
      "    heads = np.array([sum(X[:,i]) for i in range(len(X[0]))])\n",
      "    p1_old = 0\n",
      "    p2_old = 0\n",
      "    lam_old = 0\n",
      "    while((abs(lam - lam_old) + abs(p1 - p1_old) + abs(p2 - p2_old)) > 0.0001):\n",
      "        pp1 = lam * (p1 ** heads[:]) * ((1-p1)**(M - heads[:]))\n",
      "        pp2 = (1-lam)* (p2 ** heads[:]) * ((1-p2)**(M - heads[:]))\n",
      "        r1 = pp1 / (pp1 + pp2)\n",
      "        r2 = pp2 / (pp1 + pp2)\n",
      "        p1_old = p1\n",
      "        p2_old = p2\n",
      "        lam_old = lam\n",
      "        p1 = sum(r1 * heads) / (M * sum(r1))\n",
      "        p2 = sum(r2 * heads) / (M * sum(r2))\n",
      "        lam = sum(r1) / N\n",
      "    return lam, p1,p2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Part 3: Testing the Solution</h2>\n",
      "\n",
      "Examine how the method behaves w.r.t varying parameters of the generated data. For each combination you test, generate the data once and run EM 20 times with different random initialization values (the values you feed into the EM function). Then show the following in one plot for every estimated parameter separately (total of 3 plots) ($\\lambda$,$p_1$,$p_2$):\n",
      "\n",
      "- the true value (mark it with a star)\n",
      "\n",
      "- the mean (mark it with a circle)\n",
      "\n",
      "- mean + standard deviation\n",
      "\n",
      "- mean - standard deviation\n",
      "\n",
      "- minimum\n",
      "\n",
      "- maximum\n",
      "\n",
      "Add the hyperparameters to the x axis (for example using xtick).\n",
      "\n",
      "Take care that the following may occur: if the true parameters are ($\\lambda$,$p_1$,$p_2$) = (0.3,0.7,0.4) the method may estimate (0.7,0.4,0.7), i.e. determine (1-$\\lambda$) and swap the values of coins A and B. Account for this in your solution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sets = np.array([[0.5, 0.9, 0.3],[0.5,0.7,0.4], [0.5,0.6,0.5], [0.5,0.55,0.45], [0.8, 0.7,0.4], \n",
      "                 [0.8,0.6,0.4],[0.8,0.5,0.45], [0.8, 0.51,0.49], [0.6, 0.5, 0.3], [0.1,0.5,0.3]])\n",
      "N = 20\n",
      "M = 10\n",
      "# Feel free to add additional samples and experiment with different N and M\n",
      "iterations = 20\n",
      "params = np.zeros((len(sets[:,0]),iterations,3))\n",
      "for j in range(len(sets[:,0])):\n",
      "    X = generateData(sets[j,0],sets[j,1],sets[j,2],N,M)\n",
      "    i = 0\n",
      "    while(i<iterations):\n",
      "        params[j,i,:] = EM(random.random(),random.random(),random.random(),X,N,M)\n",
      "        i = i+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Run the same code for N = 200 and M = 100\n",
      "#TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Analysis</h3>\n",
      "** When does the method provide estimates close to the true values? When are the estimates further away from the true values? In general, when would you expect the method to behave well with low variance? **\n",
      "\n",
      "\n",
      "*TODO: Your analysis here*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Export your ipynb file as a pdf</h3>\n",
      "\n",
      "Make sure **all** of your code can be read within the pdfs and the individual plots aren't split across pages."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}